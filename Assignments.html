<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Ryan Gordon - Assignments</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Ryan Gordon</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">Home</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html">About</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./Assignments.html" aria-current="page">Assignments</a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Assignments</h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p><strong>Assignments:</strong></p>
<p><a href="https://docs.google.com/document/d/1111z8DyjJPs0QjofMej3um9PaZyIy73baCyUyrsMAQU/edit?usp=sharing" class="uri">https://docs.google.com/document/d/1111z8DyjJPs0QjofMej3um9PaZyIy73baCyUyrsMAQU/edit?usp=sharing</a></p>
<p><strong>6302 Group Project:</strong></p>
<p>Links to Demos:</p>
<ol type="1">
<li><p><a href="https://cometmail-my.sharepoint.com/:u:/r/personal/gnc180000_utdallas_edu/Documents/Microsoft%20Teams%20Chat%20Files/Demo-1.html?csf=1&amp;web=1&amp;e=keY0Fs">Demo-1.html</a></p></li>
<li><p><a href="https://cometmail-my.sharepoint.com/:u:/r/personal/gnc180000_utdallas_edu/Documents/Microsoft%20Teams%20Chat%20Files/Demo-2.html?csf=1&amp;web=1&amp;e=17XgRC">Demo-2.html</a></p>
<p>Scripts:</p>
<ol type="1">
<li>Analysis File:</li>
</ol>
<!-- -->
<pre><code># EPPS 6302 Group Project Analysis File
# By: Genna Campain, Ryan Gordon, Su Lin Goh, Michelle Kim

# Library
library(spotifyr)
library(magrittr)
library(geniusr)
library(dplyr)
library(tidyverse)
library(tidytext)
library(textdata)
library(stringr)
library(readr)

# Data loading and editing
load("~/Desktop/Fall 2022/Data methods/Group Project/lyrics_data.Rda")
final_df$num &lt;- seq.int(from = 1, to = 250)
final_df$year &lt;- 2018
final_df$year[which(final_df$num &gt; 50 &amp; final_df$num &lt; 101)] &lt;- 2019
final_df$year[which(final_df$num &gt; 100 &amp; final_df$num &lt; 151)] &lt;- 2020
final_df$year[which(final_df$num &gt; 150 &amp; final_df$num &lt; 201)] &lt;- 2021
final_df$year[which(final_df$num &gt; 200)] &lt;- 2022


# Paste all lyrics for year into one line of dataframe
df2 &lt;- final_df %&gt;%
  group_by(year) %&gt;%
  summarise(col = paste(lyrics, collapse=" "))

# Text analysis
sp_stop_words &lt;- spanish_stopwords &lt;- read.table("~/Desktop/Fall 2022/Data methods/Group Project/spanish_stopwords.txt", quote="\"", comment.char="") %&gt;%
  rename(word = V1)
count_result &lt;- data.frame()
afinn_result &lt;- data.frame()
bing_and_nrc_result &lt;- data.frame()
for(j in 2018:2022) {
  text &lt;- df2$col[which(df2$year == j)]
  tibble &lt;- tibble(line = 1, text = text)
  tidy_lyrics &lt;- unnest_tokens(tibble, word, text)
  data(stop_words)
  tidy_lyrics &lt;- tidy_lyrics %&gt;%
    anti_join(stop_words) %&gt;%
    anti_join(sp_stop_words)
  # Count of common words
  count &lt;- tidy_lyrics %&gt;%
    count(word, sort = TRUE) %&gt;%
    mutate(year = j)
  count_result &lt;- rbind(count_result, count)
  # Sentiment analysis using afinn
  afinn &lt;- get_sentiments("afinn")
  afinn_text &lt;- tidy_lyrics %&gt;% 
    inner_join(afinn) %&gt;% 
    summarise(sentiment = sum(value)) %&gt;% 
    mutate(method = "AFINN") %&gt;%
    mutate(year = j)
  afinn_result &lt;- rbind(afinn_result, afinn_text)
  # Sentiment analysis using bing and nrc
  bing_and_nrc &lt;- bind_rows(
    tidy_lyrics %&gt;% 
      inner_join(get_sentiments("bing")) %&gt;%
      mutate(method = "Bing et al."),
    tidy_lyrics %&gt;% 
      inner_join(get_sentiments("nrc") %&gt;% 
                   filter(sentiment %in% c("positive", 
                                           "negative"))
      ) %&gt;%
      mutate(method = "NRC")) %&gt;%
    count(method, sentiment) %&gt;%
    pivot_wider(names_from = sentiment,
                values_from = n,
                values_fill = 0) %&gt;% 
    mutate(sentiment = positive - negative) %&gt;%
    mutate(year = j)
  bing_and_nrc_result &lt;- rbind(bing_and_nrc_result, bing_and_nrc)
}

# Pull top 100 words of each year
top100words &lt;- count_result %&gt;% 
  group_by(year) %&gt;% 
  mutate(rown = row_number()) %&gt;%
  ungroup()
top100words &lt;- top100words[which(top100words$rown &lt;= 100), ]

## Replace profanity with placeholder letters
top100words$word[top100words$word == 'shit'] &lt;- 's***'
top100words$word[top100words$word == 'nigga'] &lt;- 'n****'
top100words$word[top100words$word == 'niggas'] &lt;- 'n*****'
top100words$word[top100words$word == 'bitch'] &lt;- 'b****'
top100words$word[top100words$word == 'fuck'] &lt;- 'f***'
top100words$word[top100words$word == 'ass'] &lt;- 'a**'
top100words$word[top100words$word == 'pussy'] &lt;- 'p****'
top100words$word[top100words$word == 'fuckin'] &lt;- 'f*****'
top100words$word[top100words$word == 'mothafuckin'] &lt;- 'm****f*****'

## Word cloud with top 50 words
library(wordcloud2)
library(htmlwidgets)
words2018 &lt;- top100words[which(top100words$year == 2018), ] %&gt;%
  select(word, n)
words2019 &lt;- top100words[which(top100words$year == 2019), ] %&gt;%
  select(word, n)
words2020 &lt;- top100words[which(top100words$year == 2020), ] %&gt;%
  select(word, n)
words2021 &lt;- top100words[which(top100words$year == 2021), ] %&gt;%
  select(word, n)
words2022 &lt;- top100words[which(top100words$year == 2022), ] %&gt;%
  select(word, n)
hw1 = wordcloud2(words2018, shape = 'triangle')
hw2 = wordcloud2(words2019, shape = 'triangle')
hw3 = wordcloud2(words2020, shape = 'triangle')
hw4 = wordcloud2(words2021, shape = 'triangle')
hw5 = wordcloud2(words2022, shape = 'triangle')
saveWidget(hw1,"1.html",selfcontained = F)
webshot::webshot("1.html","1.png",vwidth = 1992, vheight = 1744, delay =10)
saveWidget(hw2,"2.html",selfcontained = F)
webshot::webshot("2.html","2.png",vwidth = 1992, vheight = 1744, delay =10)
saveWidget(hw3,"3.html",selfcontained = F)
webshot::webshot("3.html","3.png",vwidth = 1992, vheight = 1744, delay =10)
saveWidget(hw4,"4.html",selfcontained = F)
webshot::webshot("4.html","4.png",vwidth = 1992, vheight = 1744, delay =10)
saveWidget(hw5,"5.html",selfcontained = F)
webshot::webshot("5.html","5.png",vwidth = 1992, vheight = 1744, delay =10)

# Identify which words are not being matched with lexicon
text &lt;- df2$col
tibble &lt;- tibble(line = 1, text = text)
tidy_lyrics &lt;- unnest_tokens(tibble, word, text)
data(stop_words)
tidy_lyrics &lt;- tidy_lyrics %&gt;%
  anti_join(stop_words) %&gt;%
  anti_join(sp_stop_words)
# Pull out words not matched to afinn
afinn &lt;- get_sentiments("afinn")
not_matched_afinn &lt;- tidy_lyrics %&gt;% 
  anti_join(afinn) %&gt;%
    unique()
# Pull out words not matched to bing and nrc
not_matched_bing &lt;- tidy_lyrics %&gt;% 
    anti_join(get_sentiments("bing")) %&gt;%
    unique()
not_matched_nrc &lt;- tidy_lyrics %&gt;% 
    anti_join(get_sentiments("nrc"))%&gt;%
    unique()
# Spanish language analysis
pos_sp &lt;- read_csv("isol/positivas_mejorada.csv", col_names = FALSE) %&gt;%
  mutate(score = 1)
neg_sp &lt;- read_csv("isol/negativas_mejorada.csv", col_names = FALSE) %&gt;%
  mutate(score = -1)
sp_sent &lt;- rbind(pos_sp, neg_sp) %&gt;%
  rename(word = X1)
# sp_text &lt;- tidy_lyrics %&gt;% 
  # inner_join(sp_sent) %&gt;% 
  # summarise(sentiment = sum(score))

## Save as CSV files
setwd("~/Desktop/Fall 2022/Data methods/Group Project")
write.csv(not_matched_afinn,"Not matched afinn.csv", row.names = FALSE)
write.csv(not_matched_bing_and_nrc,"Not matched bingnrc.csv", row.names = FALSE)

# Combine bing, spanish and self-created sentiment values
bing_sent &lt;- get_sentiments("bing") %&gt;%
  rename(score = sentiment)
bing_sent$score[bing_sent$score == 'positive'] &lt;- 1
bing_sent$score[bing_sent$score == 'negative'] &lt;- -1
our_sent &lt;- read_excel("Not matched bingnrc.xlsx") %&gt;%
  rename(score = "...3") %&gt;%
  na.omit() %&gt;%
  select(word, score)
mix_sent &lt;- rbind(bing_sent, sp_sent) %&gt;%
  rbind(our_sent)
mix_sent$score &lt;- as.numeric(mix_sent$score)

bing_sp_sent &lt;- rbind(bing_sent, sp_sent)
bing_sp_sent$score &lt;- as.numeric(bing_sp_sent$score)

# Pull out words not matched to new lexicons
not_matched_spb &lt;- tidy_lyrics %&gt;% 
  anti_join(bing_sp_sent)%&gt;%
  unique()
not_matched_mix &lt;- tidy_lyrics %&gt;% 
  anti_join(mix_sent)%&gt;%
  unique()

# Analyze with new values
mix_result &lt;- data.frame()
for(j in 2018:2022) {
  text &lt;- df2$col[which(df2$year == j)]
  tibble &lt;- tibble(line = 1, text = text)
  tidy_lyrics &lt;- unnest_tokens(tibble, word, text)
  data(stop_words)
  tidy_lyrics &lt;- tidy_lyrics %&gt;%
    anti_join(stop_words) %&gt;%
    anti_join(sp_stop_words)
  # Sentiment analysis using self-created lexicon
  mix_text &lt;- tidy_lyrics %&gt;% 
    inner_join(mix_sent) %&gt;% 
    summarise(sentiment = sum(score)) %&gt;% 
    mutate(method = "mixed") %&gt;%
    mutate(year = j)
  mix_result &lt;- rbind(mix_result, mix_text)
}

bing_sp_result &lt;- data.frame()
for(j in 2018:2022) {
  text &lt;- df2$col[which(df2$year == j)]
  tibble &lt;- tibble(line = 1, text = text)
  tidy_lyrics &lt;- unnest_tokens(tibble, word, text)
  data(stop_words)
  tidy_lyrics &lt;- tidy_lyrics %&gt;%
    anti_join(stop_words) %&gt;%
    anti_join(sp_stop_words)
  # Sentiment analysis using self-created lexicon
  bing_sp_text &lt;- tidy_lyrics %&gt;% 
    inner_join(bing_sp_sent) %&gt;% 
    summarise(sentiment = sum(score)) %&gt;% 
    mutate(method = "bing_sp") %&gt;%
    mutate(year = j)
  bing_sp_result &lt;- rbind(bing_sp_result, bing_sp_text)
}

## Create visualizations
bing &lt;- bing_and_nrc_result[which(bing_and_nrc_result$method == "Bing et al."), ] %&gt;%
  select(sentiment, year) %&gt;%
  mutate(method = "Bing") 
nrc &lt;- bing_and_nrc_result[which(bing_and_nrc_result$method == "NRC"), ]  %&gt;%
  select(sentiment, year) %&gt;%
  mutate(method = "NRC")
afinn &lt;- afinn_result %&gt;%
  select(sentiment, year, method)
bing_sp &lt;- bing_sp_result %&gt;%
  select(sentiment, year) %&gt;%
  mutate(method = "Bing_sp")
mix &lt;- mix_result %&gt;%
  select(sentiment, year) %&gt;%
  mutate(method = "Mix")
big_df &lt;- rbind(bing, nrc) %&gt;%
  rbind(afinn) %&gt;%
  rbind(bing_sp) %&gt;%
  rbind(mix) %&gt;%
  rename(Year = year, Method = method)
big_df$Year &lt;- as.factor(big_df$Year)
save(big_df, file="all sentiments combined.Rda")

### library(ggplot2)
### library(RColorBrewer)
### library(ggthemes)
ggplot(big_df,
       aes(x = Year,
           y = sentiment,
           fill = Method)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  theme_minimal() +
  labs(x = "Year", y = "Sentiment Score") + 
  scale_fill_brewer(palette = "Set1")

# Calculate summary statistics for audio analysis
load("~/Desktop/Fall 2022/Data methods/Group Project/playlist audio features.Rda")
sum_songs_ana &lt;- songs_ana %&gt;%
  group_by(year) %&gt;%
  summarise(m_dance = mean(danceability), 
            m_valence = mean(valence),
            m_acoustic = mean(acousticness))
sum_songs_ana$year &lt;- as.factor(sum_songs_ana$year)

songs_ana$year &lt;- as.factor(songs_ana$year)

ggplot(songs_ana, aes(valence, fill = year)) + 
  geom_density() +
  facet_grid(year ~ .) +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Set1") +
  labs(x = "Valence", y = "Density")

ggplot(songs_ana, aes(danceability, fill = year)) + 
  geom_density() +
  facet_grid(year ~ .) +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Set1") +
  labs(x = "Danceability", y = "Density")

ggplot(songs_ana, aes(acousticness, fill = year)) + 
  geom_density() +
  facet_grid(year ~ .) +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Set1") +
  labs(x = "Acousticness", y = "Density")

df1 &lt;- sum_songs_ana %&gt;%
  select(year, m_dance) %&gt;%
  mutate(Characteristic = "Danceability") %&gt;%
  rename(Value = m_dance)
df2 &lt;- sum_songs_ana %&gt;%
  select(year, m_valence) %&gt;%
  mutate(Characteristic = "Valence") %&gt;%
  rename(Value = m_valence)
df3 &lt;- sum_songs_ana %&gt;%
  select(year, m_acoustic) %&gt;%
  mutate(Characteristic = "Acousticness") %&gt;%
  rename(Value = m_acoustic)
sum_songs_ana &lt;- rbind(df1, df2) %&gt;%
  rbind(df3)
sum_songs_ana$Year &lt;- as.factor(sum_songs_ana$year)

ggplot(sum_songs_ana,
       aes(x = Year,
           y = Value,
           fill = Characteristic)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  theme_minimal() +
  labs(x = "Year", y = "Value") + 
  scale_fill_brewer(palette = "Set1")

# Unique words from each year
count_result &lt;- data.frame()
for(j in 2018:2022) {
  text &lt;- df2$col[which(df2$year == j)]
  tibble &lt;- tibble(line = 1, text = text)
  tidy_lyrics &lt;- unnest_tokens(tibble, word, text)
  data(stop_words)
  tidy_lyrics &lt;- tidy_lyrics %&gt;%
    anti_join(stop_words) %&gt;%
    anti_join(sp_stop_words)

  # Count of common words
  count &lt;- tidy_lyrics %&gt;%
    count(word, sort = TRUE) %&gt;%
    mutate(year = j)
  count_result &lt;- rbind(count_result, count)
}
words2018 &lt;- count_result[which(count_result$year == 2018), ] %&gt;%
  select(word)
words2019 &lt;- count_result[which(count_result$year == 2019), ] %&gt;%
  select(word)
words2020 &lt;- count_result[which(count_result$year == 2020), ] %&gt;%
  select(word)
words2021 &lt;- count_result[which(count_result$year == 2021), ] %&gt;%
  select(word)
words2022 &lt;- count_result[which(count_result$year == 2022), ] %&gt;%
  select(word)

u_words2020 &lt;- words2020 %&gt;%
  anti_join(words2018) %&gt;%
  anti_join(words2019) %&gt;%
  anti_join(words2021) %&gt;%
  anti_join(words2022) %&gt;%
  inner_join(count_result[which(count_result$year == 2020), ]) %&gt;%
  select(word, n)
u_words2020 &lt;- u_words2020[1:100,]
u_words2020$word[u_words2020$word == 'shit'] &lt;- 's***'
u_words2020$word[u_words2020$word == 'nigga'] &lt;- 'n****'
u_words2020$word[u_words2020$word == 'niggas'] &lt;- 'n*****'
u_words2020$word[u_words2020$word == 'bitch'] &lt;- 'b****'
u_words2020$word[u_words2020$word == 'fuck'] &lt;- 'f***'
u_words2020$word[u_words2020$word == 'ass'] &lt;- 'a**'
u_words2020$word[u_words2020$word == 'pussy'] &lt;- 'p****'
u_words2020$word[u_words2020$word == 'fuckin'] &lt;- 'f*****'
u_words2020$word[u_words2020$word == 'mothafuckin'] &lt;- 'm****f*****'
hw7 = wordcloud2(u_words2020, shape = 'triangle')
saveWidget(hw7,"7.html",selfcontained = F)
webshot::webshot("7.html","7.png",vwidth = 1992, vheight = 1744, delay =10)



# Analyzing covid-specific songs
text &lt;- final_df2$col
tibble &lt;- tibble(line = 1, text = text)
tidy_lyrics &lt;- unnest_tokens(tibble, word, text)
data(stop_words)
tidy_lyrics &lt;- tidy_lyrics %&gt;%
  anti_join(stop_words)
# Count of common words
count &lt;- tidy_lyrics %&gt;%
  count(word, sort = TRUE)
# Sentiment analysis using afinn
afinn &lt;- get_sentiments("afinn")
afinn_text &lt;- tidy_lyrics %&gt;% 
  inner_join(afinn) %&gt;% 
  summarise(sentiment = sum(value)) %&gt;% 
  mutate(method = "AFINN")
# Sentiment analysis using bing and nrc
bing_and_nrc &lt;- bind_rows(
  tidy_lyrics %&gt;% 
    inner_join(get_sentiments("bing")) %&gt;%
    mutate(method = "Bing et al."),
  tidy_lyrics %&gt;% 
    inner_join(get_sentiments("nrc") %&gt;% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %&gt;%
    mutate(method = "NRC")) %&gt;%
  count(method, sentiment) %&gt;%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %&gt;% 
  mutate(sentiment = positive - negative)
## word cloud
## Replace profanity with placeholder letters
count$word[count$word == 'shit'] &lt;- 's***'
count$word[count$word == 'nigga'] &lt;- 'n****'
count$word[count$word == 'niggas'] &lt;- 'n*****'
count$word[count$word == 'bitch'] &lt;- 'b****'
count$word[count$word == 'fuck'] &lt;- 'f***'
count$word[count$word == 'ass'] &lt;- 'a**'
count$word[count$word == 'pussy'] &lt;- 'p****'
count$word[count$word == 'fuckin'] &lt;- 'f*****'
count$word[count$word == 'mothafuckin'] &lt;- 'm****f*****'
hw6 = wordcloud2(count, shape = 'triangle')
saveWidget(hw6,"6.html",selfcontained = F)
webshot::webshot("6.html","6.png",vwidth = 1992, vheight = 1744, delay =10)

# Analyze counts of words not being matched
not_matched_d &lt;- c("AFINN", 5846, "Bing", 5680, "NRC", 5421, "Bing_sp", 5502, "Mix", 4618)
not_matched &lt;- matrix(not_matched_d, nrow = 5, ncol = 2, byrow = TRUE) %&gt;%
  as.data.frame()
colnames(not_matched) &lt;- c("Lexicon", "Unmatched")
not_matched$total &lt;- 37093
not_matched$Unmatched &lt;- as.numeric(not_matched$Unmatched)
not_matched$pct_unmatched &lt;- (not_matched$Unmatched/not_matched$total)*100
ggplot(not_matched,
       aes(x = Lexicon,
           y = pct_unmatched,
           fill = Lexicon)) +
  geom_bar(stat = "identity",
           position = "dodge", show.legend = FALSE) +
  theme_minimal() +
  labs(x = "Lexicon", y = "Percent of Words Unmatched") + 
  scale_fill_brewer(palette = "Set1")</code></pre>
<div class="cell">

</div>
<ol start="2" type="1">
<li>Project RMD:</li>
</ol>
<pre class="{r}---}"><code>title: "Data Methods Group Project"
author: "Genna Campain, Ryan Gordon, Su Lin Goh, Michelle Kim"
date: "9/10/2022"
output: html_document
---
# Scrape and edit top songs lists
Load packages
library(spotifyr)
library(magrittr)
library(geniusr)
library(dplyr)
library(tidyverse)
library(tidytext)
library(textdata)
library(stringr)
Access token
id &lt;- "9bd81604c1724db4b9ad68f64dd7fbfe"
secret &lt;- "791feacce6c143f5bf2ecb23d517e055"
Sys.setenv(SPOTIFY_CLIENT_ID = id)
Sys.setenv(SPOTIFY_CLIENT_SECRET = secret)
access_token &lt;- get_spotify_access_token()
token &lt;- "QPPNNpRdh3O3T-e7LbSGTeYzIefKe1ZL6CeoR26DKwRxdMbln6audf3TNViNVhEG"
Sys.setenv(GENIUS_API_TOKEN = token)
Scraping top 100 songs of the year playlists
year_id &lt;- data.frame(id = c("37i9dQZF1DXe2bobNYDtW8", "37i9dQZF1DWVRSukIED0e9", "37i9dQZF1DX7Jl5KP2eZaS", "5GhQiRkGuqzpWZSE7OU4Se", "37i9dQZF1DX18jTM2l2fJY"), year = 2018:2022)

top_songs &lt;- data.frame()
for(j in 1:5) {
playlist_id &lt;- year_id[j, 1]
year &lt;- year_id[j, 2]
tracks &lt;- get_playlist_tracks(
    playlist_id = playlist_id,
    fields = c("track.artists", "track.duration_ms", "track.explicit", "track.id", "track.name", "track.popularity", "track.album.name", "track.album.release.date")
) %&gt;%
  mutate(year = year)
top_songs &lt;- rbind(top_songs, tracks)
}
Subset to take top 50 songs by year, unpack artist names
top_songs &lt;- top_songs %&gt;% 
  group_by(year) %&gt;% 
  mutate(rown = row_number()) %&gt;%
  ungroup()
top_songs &lt;- top_songs[which(top_songs$rown &lt;= 50), ]

artists &lt;- top_songs$track.artists
artists2 &lt;- matrix(0, 0, nrow = 250, ncol = 1)
for(j in 1:250){ 
     df &lt;- artists[[j]]
     name &lt;- df$name
     artists2[j] &lt;- name
}
top_songs &lt;- cbind(top_songs, artists2)
songinfo &lt;- select(top_songs, c(track.name, artists2, year)) %&gt;%
  rename(track.artists = artists2)
# Scrape song lyrics
Edit song and artist names to match Genius website
songinfo$track.name &lt;- gsub("\\s*\\([^\\)]+\\)","",as.character(songinfo$track.name))
songinfo2018 &lt;- songinfo[which(songinfo$year == 2018), ]
songinfo2019 &lt;- songinfo[which(songinfo$year == 2019), ]
songinfo2020 &lt;- songinfo[which(songinfo$year == 2020), ]
songinfo2021 &lt;- songinfo[which(songinfo$year == 2021), ]
songinfo2022 &lt;- songinfo[which(songinfo$year == 2022), ]


# 2018
songinfo2018[19, 1] &lt;- "LOVE."
songinfo2018[15, 2] &lt;- "Lil Baby and Drake"
songinfo2018[6, 2] &lt;- "Juice wrld"
songinfo2018[13, 1] &lt;- "happier"
songinfo2018[17, 2] &lt;- "Offset and Metro Boomin"
songinfo2018[21, 2] &lt;- "Anne marie"
songinfo2018[32, 2] &lt;- "Dynoro and gigi dagostino"
songinfo2018[33, 2] &lt;- "G Eazy and Halsey"
songinfo2018[33, 1] &lt;- "Him and I"
songinfo2018[36, 1] &lt;- "Te bote"
songinfo2018[39, 1] &lt;- "1 2 3"
songinfo2018[39, 2] &lt;- "Sofia Reyes"
songinfo2018[41, 2] &lt;- "Hailee Steinfeld and Alesso"
songinfo2018[48, 1] &lt;- "Dejala Que Vuelva"
# 2019
songinfo2019[3, 2] &lt;- "Shawn Mendes and Camila Cabello"
songinfo2019[3, 1] &lt;- "Senorita"
songinfo2019[5, 1] &lt;- "Sunflower"
songinfo2019[44, 1] &lt;- "10000 hours"
songinfo2019[44, 2] &lt;- "Dan shay"
# 2020
songinfo2020[21, 2] &lt;- "Jawsh 685 and Jason Derulo"
songinfo2020[21, 1] &lt;- "Savage love laxed siren beat"
songinfo2020[26, 1] &lt;- "Senorita"
songinfo2020[26, 2] &lt;- "Shawn Mendes and Camila Cabello"
songinfo2020[38, 1] &lt;- "Sunflower"
songinfo2020[39, 1] &lt;- "Hawai"
songinfo2020[42, 1] &lt;- "ritmo bad boys for life"
songinfo2020[42, 2] &lt;- "The black eyed peas and j balvin"
songinfo2020[47, 2] &lt;- "Ariana Grande and Justin Bieber"

# 2021
songinfo2021[2, 1] &lt;- "Montero Call Me by Your Name"
songinfo2021[10, 1] &lt;- "Beggin"
songinfo2021[10, 2] &lt;- "Maneskin"
songinfo2021[12, 1] &lt;- "Dakiti"
songinfo2021[17, 2] &lt;- "Silk Sonic"
songinfo2021[21, 2] &lt;- "Tiesto"
songinfo2021[25, 2] &lt;- "Riton and Nightcrawlers"
songinfo2021[25, 1] &lt;- "Friday dopamine re edit"
songinfo2021[26, 1] &lt;- "telepatia"
songinfo2021[33, 2] &lt;- "Myke Towers and Juhn"
songinfo2021[34, 2] &lt;- "Maneskin"
songinfo2021[46, 1] &lt;- "Que Mas Pues"
songinfo2021[48, 1] &lt;- "34 35"
songinfo2021[50, 1] &lt;- "Pareja Del Ano"
songinfo2021[50, 2] &lt;- "Sebastian yatra and Myke Towers"

# 2022
songinfo2022[5, 1] &lt;- "Titi Me Pregunto"
songinfo2022[7, 1] &lt;- "Enemy"
songinfo2022[8, 1] &lt;- "quevedo bzrp music sessions vol 52"
songinfo2022[8, 2] &lt;- "Bizarrap and quevedo"
songinfo2022[10, 1] &lt;- "Running up that hill a deal with god"
songinfo2022[19, 2] &lt;- "Elley Duhe"
songinfo2022[22, 2] &lt;- "Rauw alejandro and chencho corleone"
songinfo2022[29, 2] &lt;- "Lost frequencies and calum scott"
songinfo2022[36, 1] &lt;- "I Aint Worried"
songinfo2022[39, 1] &lt;- "Una Noche en Medellin"
songinfo2022[42, 2] &lt;- "Bad Bunny &amp; Rauw Alejandro"
songinfo2022[44, 2] &lt;- "Tiesto"
Loop for scraping (for some reason loop randomly breaks if too many numbers)
# 2018
final_df &lt;- data.frame()
for(j in 48:50) {
  artist_name &lt;- songinfo2018[j, 2]
  song_title &lt;- songinfo2018[j, 1]
  df &lt;- get_lyrics_search(artist_name = artist_name, song_title = song_title)
  df &lt;- df$line
  df &lt;- as.vector(df)
  df&lt;- paste(df, collapse = " ") 
  final_df &lt;- rbind(final_df, df)
}

# 2019
for(j in 48:50) {
  artist_name &lt;- songinfo2019[j, 2]
  song_title &lt;- songinfo2019[j, 1]
  df &lt;- get_lyrics_search(artist_name = artist_name, song_title = song_title)
  df &lt;- df$line
  df &lt;- as.vector(df)
  df&lt;- paste(df, collapse = " ") 
  final_df &lt;- rbind(final_df, df)
}

# 2020
for(j in 47:50) {
  artist_name &lt;- songinfo2020[j, 2]
  song_title &lt;- songinfo2020[j, 1]
  df &lt;- get_lyrics_search(artist_name = artist_name, song_title = song_title)
  df &lt;- df$line
  df &lt;- as.vector(df)
  df&lt;- paste(df, collapse = " ") 
  final_df &lt;- rbind(final_df, df)
}

# 2021
for(j in 48:50) {
  artist_name &lt;- songinfo2021[j, 2]
  song_title &lt;- songinfo2021[j, 1]
  df &lt;- get_lyrics_search(artist_name = artist_name, song_title = song_title)
  df &lt;- df$line
  df &lt;- as.vector(df)
  df&lt;- paste(df, collapse = " ")
  final_df &lt;- rbind(final_df, df)
}

# 2022
final_df &lt;- data.frame()
for(j in 44:50) {
  artist_name &lt;- songinfo2022[j, 2]
  song_title &lt;- songinfo2022[j, 1]
  df &lt;- get_lyrics_search(artist_name = artist_name, song_title = song_title)
  df &lt;- df$line
  df &lt;- as.vector(df)
  df&lt;- paste(df, collapse = " ")
  final_df &lt;- rbind(final_df, df)
}

colnames(final_df)[1] &lt;- "lyrics"
setwd("~/Desktop/Fall 2022/Data methods/Group Project")
save(final_df, file="lyrics_data.Rda")
Label column and add year
load("~/Desktop/Fall 2022/Data methods/Group Project/lyrics_data.Rda")
final_df$num &lt;- seq.int(from = 1, to = 250)
final_df$year &lt;- 2018
final_df$year[which(final_df$num &gt; 50 &amp; final_df$num &lt; 101)] &lt;- 2019
final_df$year[which(final_df$num &gt; 100 &amp; final_df$num &lt; 151)] &lt;- 2020
final_df$year[which(final_df$num &gt; 150 &amp; final_df$num &lt; 201)] &lt;- 2021
final_df$year[which(final_df$num &gt; 200)] &lt;- 2022
Paste all lyrics for year into one line of dataframe
https://stackoverflow.com/questions/54805201/how-to-paste-all-string-values-in-a-column-together-as-one 
# insert year here
df2 &lt;- final_df %&gt;%
  group_by(year) %&gt;%
  summarise(col = paste(lyrics, collapse=" "))
df2 &lt;- df2 %&gt;%
  ungroup()
write.csv(df2,"lyrics_oneline.csv", row.names = FALSE)
Text analysis
count_result &lt;- data.frame()
afinn_result &lt;- data.frame()
bing_and_nrc_result &lt;- data.frame()
for(j in 2018:2021) {
text &lt;- df2$col[which(df2$year == j)]
tibble &lt;- tibble(line = 1, text = text)
tidy_lyrics &lt;- unnest_tokens(tibble, word, text)
data(stop_words)
tidy_lyrics &lt;- tidy_lyrics %&gt;%
  anti_join(stop_words)
# Count of common words
count &lt;- tidy_lyrics %&gt;%
  count(word, sort = TRUE) %&gt;%
  mutate(year = j)
count_result &lt;- rbind(count_result, count)
# Sentiment analysis using afinn
afinn &lt;- get_sentiments("afinn")
afinn_text &lt;- tidy_lyrics %&gt;% 
  inner_join(afinn) %&gt;% 
  summarise(sentiment = sum(value)) %&gt;% 
  mutate(method = "AFINN") %&gt;%
  mutate(year = j)
afinn_result &lt;- rbind(afinn_result, afinn_text)
# Sentiment analysis using bing and nrc
bing_and_nrc &lt;- bind_rows(
  tidy_lyrics %&gt;% 
    inner_join(get_sentiments("bing")) %&gt;%
    mutate(method = "Bing et al."),
   tidy_lyrics %&gt;% 
    inner_join(get_sentiments("nrc") %&gt;% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %&gt;%
    mutate(method = "NRC")) %&gt;%
  count(method, sentiment) %&gt;%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %&gt;% 
  mutate(sentiment = positive - negative) %&gt;%
  mutate(year = j)
bing_and_nrc_result &lt;- rbind(bing_and_nrc_result, bing_and_nrc)
}

Get audio features
year_id &lt;- data.frame(id = c("37i9dQZF1DXe2bobNYDtW8", "37i9dQZF1DWVRSukIED0e9", "37i9dQZF1DX7Jl5KP2eZaS", "5GhQiRkGuqzpWZSE7OU4Se", "37i9dQZF1DX18jTM2l2fJY"), year = 2018:2022)

songs_ana &lt;- data.frame()
for(j in 1:5) {
playlist_id &lt;- year_id[j, 1]
year &lt;- year_id[j, 2]
tracks &lt;- get_playlist_audio_features(
  "spotify",
  playlist_id) %&gt;%
  mutate(year = year)
songs_ana &lt;- rbind(songs_ana, tracks)
}
songs_ana &lt;- inner_join(songs_ana, top_songs, by = c("track.id", "year"))
songs_ana &lt;- songs_ana %&gt;%
  select(danceability, energy, key, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, year, track.name.y, track.id)
save(songs_ana, file="playlist audio features.Rda")
# write.csv(songs_ana,"playlist audio features.csv", row.names = FALSE)
Get lyrics for songs specifically about COVID-19
covid_songs &lt;- read_excel("covid songs.xlsx") %&gt;%
  as.matrix()
final_df2 &lt;- data.frame()
for(j in 7:23) {
  artist_name &lt;-covid_songs[j, 2]
  song_title &lt;- covid_songs[j, 1]
  df &lt;- get_lyrics_search(artist_name = artist_name, song_title = song_title)
  df &lt;- df$line
  df &lt;- as.vector(df)
  df&lt;- paste(df, collapse = " ") 
  final_df2 &lt;- rbind(final_df2, df)
}
colnames(final_df2) &lt;- "lyrics"
final_df2 &lt;- final_df2 %&gt;%
  summarise(col = paste(lyrics, collapse=" "))
save(final_df2, file="covid songs.Rda")



</code></pre></li>
</ol>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>